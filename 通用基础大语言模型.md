|名称  |  来源   | 说明  |状态   | 备注  |
|  ----  | ----  |----  | ----  |----  |
| 《Training language models to follow instructions with human feedback》 | arxiv 2022 | OpenAI的InstructGPT：<br/>训练了三个模型（1.3B、6B、175B），其中1.3B的效果就比175B的GPT-3效果好；<br/>主要的核心SFT+MR+PPO；<br/>训练的数据集也比较小：SFT-13k，RM-33k，PPO-31k | NULL | NULL |
| 《Scaling Instruction-Finetuned Language Models》| arXiv2022| Google的FLAN：<br/> Instruct tuning；<br/>基于PaLM和T5进行的实验；| NULL | NULL |
| 《Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism》| arXiv2020| 英伟达的Megatron LM：<br/>核心是张量并行（数据并行、张量并行、Pipeline并行）；<br/>在BERT和GPT-2上做了验证；<br/>只需做部分代码插入，不需要专门的框架或者编译器；<br/>李沐的paper分享也有介绍；| NULL |参考：https://zhuanlan.zhihu.com/p/366906920|
| NULL  | NULL |NULL |NULL |NULL |
| NULL  | NULL |NULL |NULL |NULL |
| NULL  | NULL |NULL |NULL |NULL |
| NULL  | NULL |NULL |NULL |NULL |
| NULL  | NULL |NULL |NULL |NULL |
| NULL  | NULL |NULL |NULL |NULL |
| NULL  | NULL |NULL |NULL |NULL |
| NULL  | NULL |NULL |NULL |NULL |
