|名称  |  来源   | 说明  |状态   | 备注  |
|  ----  | ----  |----  | ----  |----  |
| 《Hierarchical Topic Models and the Nested Chinese Restaurant Process》  | NULL |NULL |NULL |https://blog.csdn.net/hohaizx/article/details/94619576 |
| 《Topic Modeling for Personalized Recommendation of Volatile Items》  | PKDD2010 |比较老的一篇;<br/>具体内容没特别看懂;<br/>应用在特殊场景的LDA优化（比如数据比较短）;<br/>重点是LDA，而不是推荐，推荐只是验证场景; |done |NULL |
| 《Topic Memory Networks for Short Text Classification》  | EMNLP 2018 |腾讯AI Lab;<br/>神经主题模型+memory net+分类; |done |NULL |
| 《Mixing Dirichlet Topic Models and Word Embeddings to Make lda2vec》| arXiv2016|神经网络版本LDA：<br/>1 将词向量和主题向量映射到统一空间；<br/>2 输出词向量、LDA向量（副产品）、主题分布、主题词（通过词与主题的相似度计算）；<br/>3 主题相关部分没看懂，没看出和LDA有什么关系？<br/>4 LDA的损失没看懂，LDA的似然？|NULL |NULL |
| 《Discovering Discrete Latent Topics with Neural Variational Inference》| ICML2017|基于深度学习的主题模型：<br/>1 使用重参数化技巧；<br/>2 总体上没怎么看懂；|NULL |NULL || 《Autoencoding Variational Inference For Topic Models》| arXiv2017|基于神经网络的LDA：<br/>1 有github代码|NULL |NULL |
| 《Federated Topic Modeling》  | International Conference on Information and Knowledge Management 2019 |Familia的扩展阅读；<br/>基于联邦学习做主题模型？ |NULL |NULL |
| 《ATM:Adversarial-neural Topic Model》  | journal Information Processing & Management 2019 |NULL |NULL |NULL |
| NULL  | NULL |NULL |NULL |NULL |
| NULL  | NULL |NULL |NULL |NULL |
| NULL  | NULL |NULL |NULL |NULL |
| NULL  | NULL |NULL |NULL |NULL |
| NULL  | NULL |NULL |NULL |NULL |
| NULL  | NULL |NULL |NULL |NULL |
| NULL  | NULL |NULL |NULL |NULL |
