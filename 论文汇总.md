|  名称   | 目录  |
| ----  |----  | 
| NULL |NULL |
| NULL |NULL |
| NULL |NULL |
| 《ReWOO: Decoupling Reasoning from Observations for Efficient Augmented Language Models》 |大模型增强与应用 |
| 《Let’s Verify Step by Step》 |通用基础大语言模型 |
| 《Solving math word problems with processand outcome-based feedback》 |通用基础大语言模型 |
| 《LLMs for Knowledge Graph Construction and Reasoning: Recent Capabilities and Future Opportunities》 |大模型增强与应用 |
| 《Unlimiformer: Long-Range Transformers with Unlimited Length Input》 |大模型增强与应用 |
| 《AlpacaFarm: A Simulation Framework for Methods that Learn from Human Feedback》 |通用基础大语言模型 |
| 《PaLM 2 Technical Report》 |通用基础大语言模型 |
| 《GPT-4 Technical Report》 |通用基础大语言模型 |
| 《Deep Reinforcement Learning from Human Preferences》 |通用基础大语言模型 |
| 《A Survey of Large Language Models》 |通用基础大语言模型 |
| 《Toolformer: Language Models Can Teach Themselves to Use Tools》 |大模型增强与应用 |
| 《A Cookbook of Self-Supervised Learning》 |图像预训练模型 |
| 《RRHF: Rank Responses to Align Language Models with Human Feedback without tears》 |通用基础大语言模型 |
| 《OpenAssistant Conversations - Democratizing Large Language Model Alignment》 |通用基础大语言模型 |
| 《Tool Learning with Foundation Models》 |大模型增强与应用 |
| 《WebGPT: Browser-assisted question-answering with human feedback》 |大模型增强与应用 |
| 《REACT: SYNERGIZING REASONING AND ACTING IN LANGUAGE MODELS》 |大模型增强与应用 |
| 《HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in Hugging Face》 |大模型增强与应用 |
| 《OPT: Open Pre-trained Transformer Language Models》 |文本预训练模型 |
| 《BLOOM: A 176B-Parameter Open-Access Multilingual Language Model》 |文本预训练模型 |
| 《BloombergGPT: A Large Language Model for Finance》 |文本预训练模型 |
| 《Check Your Facts and Try Again: Improving Large Language Models with External Knowledge and Automated Feedback》 |大模型增强与应用 |
| 《Training a Helpful and Harmless Assistant with Reinforcement Learning from Human Feedback》 |通用基础大语言模型 |
| 《Augmented Language Models: a Survey》 |大模型增强与应用 |
| 《OpenPrompt: An Open-source Framework for Prompt-learning》 |大模型增强与应用 |
| 《Delta Tuning: A Comprehensive Study of Parameter Efficient Methods for Pre-trained Language Models》 |大模型增强与应用 |
| 《Learning to summarize from human feedback》 |摘要生成 |
| 《Recursively Summarizing Books with Human Feedback》 |摘要生成 |
| 《ChatGPT for Robotics:Design Principles and Model Abilities》 |其他 |
| 《Learning by Distilling Context》 |大模型增强 |
| 《LLaMA: Open and Efficient Foundation Language Models》 |通用基础大语言模型 |
| 《LARGE LANGUAGE MODELS ARE HUMAN-LEVEL PROMPT ENGINEERS》 |大模型增强与应用 |
| 《Recipes for building an open-domain chatbot》 |闲聊对话&开放域问答 |
| 《Poly-encoders: architectures and pre-training strategies for fast and accurate multi-sentence scoring》 |文本相似度计算 |
| 《PEER: A Collaborative Language Model》 |通用基础大语言模型 |
| 《Improving alignment of dialogue agents via targeted human judgements》 |通用基础大语言模型 |
| 《LaMDA: Language Models for Dialog Applications》 |通用基础大语言模型 |
| 《Constitutional AI: Harmlessness from AI Feedback》 |通用基础大语言模型 |
| 《DOC: Improving Long Story Coherence With Detailed Outline Control》 |小说&剧本 |
| 《Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism》 |训练加速 |
| 《Scaling Instruction-Finetuned Language Models》 |通用基础大语言模型 |
| 2023-《Training language models to follow instructions with human feedback》 |2023-通用基础大语言模型 |
| 《Co-Writing Screenplays and Theatre Scripts with Language Models An Evaluation by Industry Professionals》 |小说&剧本 |
| 《Re3: Generating Longer Stories With Recursive Reprompting and Revision》 |小说&剧本 |
| 《Kuaipedia: a Large-scale Multi-modal Short-video Encyclopedia》 |标签体系&标签扩展&兴趣标签&概念标签 |
| 《FLAT: Chinese NER Using Flat-Lattice Transformer》 |命名实体识别 |
| 《Unified Structure Generation for Universal Information Extraction》 |通用/统一信息抽取 |
| 2022-《TabTransformer: Tabular Data Modeling Using Contextual Embeddings》 |2022-表格特征融合 |
| 《See Better Before Looking Closer: Weakly Supervised Data Augmentation Network for Fine-Grained Visual Classification》 |数据增强 |
|《Grad-CAM:Visual Explanations from Deep Networks via Gradient-based Localization》|模型可解释性|
| 《PointNet: Deep Learning on Point Sets for 3D Classification and Segmentation》 |3D视觉 |
| 《Moire Photo Restoration Using Multiresolution Convolutional Neural Networks》 |图像增强/去噪/生成 |
| 《TextAttack: A Framework for Adversarial Attacks, Data Augmentation, and Adversarial Training in NLP》 |对抗攻击 |
| 《UNIMO: Towards Unified-Modal Understanding and Generation via Cross-Modal Contrastive Learning》 |多模态 |
| 《DeepFace: Closing the Gap to Human-Level Performance in Face Verification》 |人脸识别 |
| 《End-to-End Text Recognition with Convolutional Neural Networks》 |OCR |
| 《Fully Convolutional Networks for Semantic Segmentation》 |语义分割 |
| 《You Only Look Once: Unified, Real-Time Object Detection》 |目标检测 |
| 《Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks》 |目标检测 |
| 《Fast R-CNN》 |目标检测 |
| 《Rich feature hierarchies for accurate object detection and semantic segmentation》 |目标检测 |
| 《ImageNet Classification with Deep Convolutional Neural Networks》 |CNN |
| 《Network In Network》 |CNN |
| 《VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION》 |CNN |
| 《Going deeper with convolutions》 |CNN |
| 《Deep Residual Learning for Image Recognition》 |CNN |
| 《Deep Residual Learning for Image Recognition》 |CNN |
| 《Aggregated Residual Transformations for Deep Neural Networks》 |CNN |
| 《FRACTALNET:ULTRA-DEEP NEURAL NETWORKS WITHOUT RESIDUALS》 |CNN |
| 《Finding Structure in Time 》 |RNN |
| 《A State-of-the-Art Survey on Deep Learning Theory and Architectures》 |机器学习&深度学习综述 |
| 《Deep Learning》 |机器学习&深度学习综述 |
| 《learning internal representation by error propagation》 |DNN |
| 《LONG SHORT-TERM MEMORY》 |RNN |
| 《Gradient-Based Learning Applied to Document Recognition》 |CNN |
| 《Attention Is All You Need》 |Transformer |
| 《Star-Transformer》 |Transformer |
| 《Transformer-XL: Language Modeling with Longer-Term Dependency》 |Transformer |
| 《An Introductory Survey on Attention Mechanisms in NLP Problems》 |Attention机制&指针网络&记忆网络&深度图灵机 |
| 《Pointer Networks》 |Attention机制&指针网络&记忆网络&深度图灵机 |
| 《Attention-Based LSTM for Psychological Stress Detection from Spoken Language Using Distant Supervision》 |Attention机制&指针网络&记忆网络&深度图灵机 |
| 《End-To-End Memory Networks》 |Attention机制&指针网络&记忆网络&深度图灵机 |
| 《Neural Turing Machines》 |Attention机制&指针网络&记忆网络&深度图灵机 |
| 《Adversarial Attacks on Deep Learning Models in Natural Language Processing: A Survey》 |对抗攻击 |
| 《TextAttack: A Framework for Adversarial Attacks, Data Augmentation, and Adversarial Training in NLP》 |对抗攻击 |
| 《Tackling Graphical NLP problems with Graph Recurrent Networks》 |图网络 |
| 《阿尔伯塔大学博士毕业论文：基于图结构的自然语言处理》 |图网络 |
| 《Convolutional Networks on Graphs for Learning Molecular Fingerprints》 |图网络 |
| 《SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS》 |图网络 |
| 《The graph neural network model》 |图网络 |
| 《Deepwalk: Online learning of social representations》 |图网络 |
| 《SkipGram model on the generated random walks》 |图网络 |
| 《HOW POWERFUL ARE GRAPH NEURAL NETWORKS?》 |图网络 |
| 《Learning Convolutional Neural Networks for Graphs》 |图网络 |
| 《Graph Neural Networks:A Review of Methods and Applications》 |图网络 |
| 《A Comprehensive Survey on Graph Neural Networks》 |图网络 |
| 《Deep Learning on Graphs: A Survey》 |图网络 |
| 《LINE: Large-scale Information Network Embedding》 |图网络 |
| 《Graph Attention Networks》 |图网络 |
| 《struc2vec: Learning Node Representations from Structural Identity》 |图网络 |
| 《GraphSAINT: Graph Sampling Based Inductive Learning Method》 |图网络 |
| 《GraphSage: Graph Sampling Based Inductive Learning Method》 |图网络 |
| 《DROPEDGE: TOWARDS DEEP GRAPH CONVOLUTIONAL NETWORKS ON NODE CLASSIFICATION》 |图网络 |
| 《Evolution of Transfer Learning in Natural Language Processing》 |迁移学习 |
| 《Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer》 |迁移学习 |
| 《Domain-Adversarial Training of Neural Networks》 |领域适应 |
| 《Auto-WEKA: Combined Selection and Hyperparameter Optimization of Classification Algorithms》 |AutoML |
| 《AutoGluon-Tabular: Robust and Accurate AutoML for Structured Data》 |AutoML |
| 《A Survey on Causal Inference》 |因果推断 |
| 《迈向第三代人工智能》 |常识AI |
| 《DEEP LEARNING FOR SYSTEM 2 PROCESSING，YOSHUA BENGIO》 |常识AI |
| 《FROM SYSTEM 1 DEEP LEARNING TO SYSTEM 2 DEEP LEARNING,YOSHUA BENGIO》 |常识AI |
| 《Cognitive Graph for Multi-Hop Reading Comprehension at Scale》 |常识AI |
| 《Auto-Encoding Variational Bayes》 |贝叶斯神经网络 |
| 《Cold-Start and Interpretability: Turning Regular Expressions into Trainable Recurrent Neural Networks》 |神经逻辑推理 |
| 《Neural Logic Reasoning》 |神经逻辑推理 |
| 《Recent Trends in Deep Learning Based Natural Language Processing》 |自然语言处理综述 |
| 《Pre-trained Models for Natural Language Processing: A Survey》 |文本预训练模型 |
| 《Semi-supervised Sequence Learning》 |文本预训练模型 |
| 《Learned in Translation: Contextualized Word Vectors》 |文本预训练模型 |
| 《Semi-supervised sequence tagging with bidirectional language models》 |文本预训练模型 |
| 《Universal Language Model Fine-tuning for Text Classification》 |文本预训练模型 |
| 《Deep contextualized word representation》 |文本预训练模型 |
| 《Improving Language Understanding by Generative Pre-Training》 |文本预训练模型 |
| 《Language Models are Unsupervised Multitask Learners》 |文本预训练模型 |
| 《Language Models are Few-Shot Learners》 |文本预训练模型 |
| 《BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding》 |文本预训练模型 |
| 《Cross-lingual Language Model Pretraining》 |文本预训练模型 |
| 《MASS: Masked Sequence to Sequence Pre-training for Language Generation》 |文本预训练模型 |
| 《Unified Language Model Pre-training for Natural Language Understanding and Generation》 |文本预训练模型 |
| 《UniLMv2: Pseudo-Masked Language Models for Unified Language Model Pre-Training》 |文本预训练模型 |
| 《MPNet: Masked and Permuted Pre-training for Language Understanding》 |文本预训练模型 |
| 《RoBERTa: A Robustly Optimized BERT Pretraining Approach》 |文本预训练模型 |
| 《ALBERT: A Lite BERT for Self-supervised Learning of Language Representations》 |文本预训练模型 |
| 《Pre-Training with Whole Word Masking for Chinese BERT》 |文本预训练模型 |
| 《ERNIE: Enhanced Language Representation with Informative Entities》 |文本预训练模型 |
| 《ERNIE: Enhanced Representation through Knowledge Integration》 |文本预训练模型 |
| 《ERNIE 2.0: A CONTINUAL PRE-TRAINING FRAMEWORK FORLANGUAGE》 |文本预训练模型 |
| 《ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators》 |文本预训练模型 |
| 《K-BERT: Enabling Language Representation with Knowledge Graph》 |文本预训练模型 |
| 《StructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding》 |文本预训练模型 |
| 《Semantics-aware BERT for Language Understanding》 |文本预训练模型 |
| 《XLNet: Generalized Autoregressive Pretraining for Language Understanding》 |文本预训练模型 |
| 《Longformer: The Long-Document Transformer》 |文本预训练模型 |
| 《Big Bird: Transformers for Longer Sequences》 |文本预训练模型 |
| 《Well-Read Students Learn Better: On the Importance of Pre-training Compact Models》 |文本预训练模型 |
| 《ALBERT: A Lite BERT for Self-supervised Learning of Language Representations》 |文本预训练模型 |
| 《DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter》 |文本预训练模型 |
| 《TinyBERT: Distilling BERT for Natural Language Understanding》 |文本预训练模型 |
| 《FastBERT: a Self-distilling BERT with Adaptive Inference Time》 |文本预训练模型 |
| 《Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer》 |文本预训练模型 |
| 《Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism》 |文本预训练模型 |
| 《THE COST OF TRAINING NLP MODELS A CONCISE OVERVIEW》 |文本预训练模型 |
| 《SpanBERT: Improving Pre-training by Representing and Predicting Spans》 |文本预训练模型 |
| 《Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks》 |文本预训练模型 |
| 《Pre-Training with Whole Word Masking for Chinese BERT》 |文本预训练模型 |
| 《NEZHA: Neural Contextualized Representation for Chinese Language Understanding》 |文本预训练模型 |
| 《ZEN: Pre-training Chinese (Z) Text Encoder Enhanced by N-gram Representations 》 |文本预训练模型 |
| 《Revisiting Pre-Trained Models for Chinese Natural Language Processing》 |文本预训练模型 |
| 《Efficient Estimation of Word Representations in Vector Space》 |文本向量化 |
| 《Distributed Representations of Words and Phrases and their Compositionality》 |文本向量化 |
| 《word2vec Parameter Learning Explained》 |文本向量化 |
| 《word2vec Explained: Deriving Mikolov et al.’s Negative-Sampling Word-Embedding Method》 |文本向量化 |
| 《Enriching Word Vectors with Subword Information》 |文本向量化 |
| 《Bag of Tricks for Efficient Text Classification》 |文本向量化 |
| 《A Neural Probabilistic Language Model》 |文本向量化 |
| 《Universal Sentence Encoder for English》 |文本向量化 |
| 《Distributed Representations of Sentences and Documents》 |文本向量化 |
| 《A Convolutional Neural Network for Modelling Sentences》 |文本向量化 |
| 《Multi-Criteria Chinese Word Segmentation with Transformer》 |中文分词 |
| 《Multi-Grained Chinese Word Segmentation》 |中文分词 |
| 《基于文档主题结构的关键词抽取方法研究》 |关键词提取 |
| 《Topic-Aware Neural Keyphrase Generation for Social Media Language》 |关键词提取 |
| 《Context-Aware Document Term Weighting for Ad-Hoc Search》 |关键词提取 |
| 《Title-Guided Encoding for Keyphrase Generation》 |关键词提取 |
| 《深度文本匹配综述》 |文本相似度计算 |
| 《A Deep Look into Neural Ranking Models for Information Retrieval》 |文本相似度计算 |
| 《Deep Learning Based Text Classification: A Comprehensive Review》 |文本分类 |
| 《Hierarchical Multi-Label Classification Networks》 |文本分类 |
| 《Large-Scale Hierarchical Text Classification with Recursively Regularized Deep Graph-CNN》 |文本分类 |
| 《Hierarchical Taxonomy-Aware and Attentional Graph Capsule RCNNs for Large-Scale Multi-Label Text Classification》 |文本分类 |
| 《Learning Deep Latent Spaces for Multi-Label Classification》 |文本分类 |
| 《Joint Embedding of Words and Labels for Text Classification》 |文本分类 |
| 《Enhancing Local Feature Extraction with Global Representation for Neural Text Classification》 |文本分类 |
| 《Description Based Text Classification with Reinforcement Learning》 |文本分类 |
| 《Document Modeling with Gated Recurrent Neural Network for Sentiment Classification》 |文本分类 |
| 《Neural Attentive Bag-of-Entities Model for Text Classification》 |文本分类 |
| 《An Interactive Multi-Task Learning Network for End-to-End Aspect-Based Sentiment Analysis》 |情感分析 |
| 《Deep Learning for Aspect-Level Sentiment Classification: Survey, Vision, and Challenges》 |情感分析 |
| 《Deep learning for sentiment analysis: A survey》 |情感分析 |
| 《Hierarchical Topic Models and the Nested Chinese Restaurant Process》 |主题模型 |
| 《Topic Modeling for Personalized Recommendation of Volatile Items》 |主题模型 |
| 《Topic Memory Networks for Short Text Classification》 |主题模型 |
| 《Mixing Dirichlet Topic Models and Word Embeddings to Make lda2vec》 |主题模型 |
| 《Discovering Discrete Latent Topics with Neural Variational Inference》 |主题模型 |
| 《Federated Topic Modeling》 |主题模型 |
| 《ATM:Adversarial-neural Topic Model》 |主题模型 |
| 《Neural Machine Reading Comprehension: Methods and Trends》 |阅读理解 |
| 《Neural Reading Comprehension And Beyond》 |阅读理解 |
| 《Get To The Point: Summarization with Pointer-Generator Networks》 |文本改写&生成 |
| 《Rigid Formats Controlled Text Generation》 |文本改写&生成 |
| 《CGMH: Constrained Sentence Generation by Metropolis-Hastings Sampling》 |文本改写&生成 |
| 《UNSUPERVISED PARAPHRASE GENERATION USING PRE-TRAINED LANGUAGE MODELS》 |文本改写&生成 |
| 《FASPell: A Fast, Adaptable, Simple, Powerful Chinese Spell Checker Based On DAE-Decoder Paradigm》 |文本检错&纠错 |
| 《文本纠错的探索与实践》平安人寿：陈乐清 |文本检错&纠错  |
| 《Get To The Point: Summarization with Pointer-Generator Network》 |摘要生成 |
| 《Encode, Tag, Realize: High-Precision Text Editing》 |摘要生成 |
| 《Multi-Source Pointer Network for Product Title Summarization》 |摘要生成 |
| 《Abstractive Summarization: A Survey of the State of the Art》 |摘要生成 |
| 《Aspect-Aware Multimodal Summarization for Chinese E-Commerce Products》 |摘要生成 |
| 《3D Convolutional Neural Networks for Human Action Recognition》 |视频分类 |
| 《Aggregating local descriptors into a compact image representation》 |图片视频向量化（特征提取） |
| 《NetVLAD: CNN architecture for weakly supervised place recognition》 |图片视频向量化（特征提取） |
| 《NeXtVLAD: An Efficient Neural Network to Aggregate Frame-level Features for Large-scale Video Classification》 |图片视频向量化（特征提取） |
| 《First Order Motion Model for Image Animation》 |视觉应用 |
| 《CNN ARCHITECTURES FOR LARGE-SCALE AUDIO CLASSIFICATION》 |智能语音 |
| 《Multimodal Machine Learning: A Survey and Taxonomy》 |多模态 |
| 《ERNIE-VIL: KNOWLEDGE ENHANCED VISION-LANGUAGE REPRESENTATIONS THROUGH SCENE GRAPH》 |多模态 |
| 《VideoBERT: A Joint Model for Video and Language Representation Learning》 |多模态 |
| 《VistaNet: Visual Aspect Attention Network for Multimodal Sentiment Analysis》 |多模态 |
| 《Supervised Multimodal Bitransformers for Classifying Images and Text》 |多模态 |
| 《Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks》 |多模态 |
| 《Tensor fusion network for multimodal sentiment analysis》 |多模态 |
| 《NetVLAD: CNN architecture for weakly supervised place recognition》 |序列特征处理 |
| 《Neural Approaches to Conversational AI Question Answering, Task-Oriented Dialogues and Social Chatbots》 |务型对话 |
| 《The Dialog State Tracking Challenge Series: A Review》 |务型对话 |
| 《MACHINE LEARNING FOR DIALOG STATE TRACKING:A REVIEW》 |务型对话 |
| 《Deep Neural Network Approach for the Dialog State Tracking Challenge》 |务型对话 |
| 《BERT for Joint Intent Classifification and Slot Filling》 |务型对话 |
| 《Task-Oriented Dialogue as Dataflow Synthesis》 |务型对话 |
| 《Transferable Multi-Domain State Generator for Task-Oriented Dialogue Systems》 |务型对话 |
| 《FAQ Retrieval using Query-Question Similarity and BERT-Based Query-Answer Relevance》 |QA对话 |
| 《PLATO: Pre-trained Dialogue Generation Model with Discrete Latent Variable》 |闲聊对话&开放域问答 |
| 《PLATO-2: Towards Building an Open-Domain Chatbot via Curriculum Learning》 |闲聊对话&开放域问答 |
| 《Improving Multi-turn Dialogue Modelling with Utterance ReWriter》 |闲聊对话&开放域问答 |
| 《Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models》 |闲聊对话&开放域问答 |
| 《A Neural Conversational Model》 |闲聊对话&开放域问答 |
| 《The Design and Implementation of XiaoIce, an Empathetic Social Chatbot》 |闲聊对话&开放域问答 |
| 《Challenges in Building Intelligent Open-domain Dialog Systems》 |闲聊对话&开放域问答 |
| 《Introduction to Neural Network based Approaches for Question Answering over Knowledge Graphs》 |图谱问答 |
| 《Know More about Each Other: Evolving Dialogue Strategy via Compound Assessment》 |对话评估&强化学习 |
| 《A Survey of Techniques for Constructing Chinese Knowledge Graphs and Their Applications 》 |知识图谱综述 |
| 《A Survey on Deep Learning for Named Entity Recognition》 |命名实体识别 |
| 《Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data》 |命名实体识别 |
| 《Bidirectional LSTM-CRF Models for Sequence Tagging》 |命名实体识别 |
| 《Neural Architectures for Named Entity Recognition》 |命名实体识别 |
| 《Chinese NER Using Lattice LSTM》 |命名实体识别 |
| 《Simplify the Usage of Lexicon in Chinese NER》 |命名实体识别 |
| 《Learning Named Entity Tagger using Domain-Specific Dictionary》 |命名实体识别 |
| 《Neural Architectures for Fine-grained Entity Type Classification》 |命名实体识别 |
| 《An attentive fine-grained entity typing model with latent type representation》 |命名实体识别 |
| 《Hierarchical Entity Typing via Multi-level Learning to Rank》 |命名实体识别 |
| 《Deep Exhaustive Model for Nested Named Entity Recognition》 |命名实体识别 |
| 《A Boundary-aware Neural Model for Nested Named Entity Recognition》 |命名实体识别 |
| 《TENER: Adapting Transformer Encoder for Named Entity Recognition》 |命名实体识别 |
| 《Joint Learning of Named Entity Recognition and Entity Linking》 |命名实体识别 |
| 《Multilingual Named Entity Recognition Using Pretrained Embeddings, Attention Mechanism and NCRF》 |命名实体识别 |
| 《Hierarchically-Refined Label Attention Network for Sequence Labeling》 |命名实体识别 |
| 《Fast and Accurate Entity Recognition with Iterated Dilated Convolutions》 |命名实体识别 |
| 《Learning to Bootstrap for Entity Set Expansion》 |实体扩展 |
| 《Classifying Relations by Ranking with Convolutional Neural Networks》 |关系抽取 |
| 《End-to-End Relation Extraction using LSTMs on Sequences and Tree Structures》 |关系抽取 |
| 《Joint entity and relation extraction based on a hybrid neural network》 |关系抽取 |
| 《Joint Extraction of Entities and Relations Based on a Novel Tagging Scheme》 |关系抽取 |
| 《FewRel: A Large-Scale Supervised Few-Shot Relation Classification Dataset with State-of-the-Art Evaluation》 |关系抽取 |
| 《Joint Extraction of Entities and Relations with a Hierarchical Multi-task Tagging Model》 |关系抽取 |
| 《A Hierarchical Framework for Relation Extraction with Reinforcement Learning》 |关系抽取 |
| 《Pre-training of Deep Contextualized Embeddings of Words and Entities for Named Entity Disambiguation》 |实体链接（消歧&归一化） |
| 《Multimodal Attribute Extraction》 |属性抽取 |
| 《Deep Learning based Recommender System: A Survey and New Perspectives》 |推荐 |
| 《推荐系统调研报告及综述》 |推荐 |
| 《Deep Neural Networks for YouTube Recommendations》 |推荐 |
| 《Deep Crossing: Web-Scale Modeling without Manually Crafted Combinatorial Features》 |推荐 |
| 《Deep & Cross Network for Ad Click Predictions》 |推荐 |
| 《MOBIUS: Towards the Next Generation of Query-Ad Matching in Baidu’s Sponsored Search》 |推荐 |
| 《Sampling-Bias-Corrected Neural Modeling for Large Corpus Item Recommendations 》 |推荐 |
| 《bipartite graph neural networks for efficient node representation learning》 |推荐 |
| 《Wide & Deep Learning for Recommender Systems》 |推荐 |
| 《SESSION-BASED RECOMMENDATIONS WITH RECURRENT NEURAL NETWORKS》 |推荐 |
| 《Semantic search on text and knowledge bases》 |搜索 |
| 《A Deep Generative Approach to Search Extrapolation and Recommendation》 |搜索 |
| 《A User-Centered Concept Mining System for Query and Document Understanding at Tencent》 |标签体系&标签扩展&兴趣标签&概念标签 |
| 《GIANT: Scalable Creation of a Web-scale Ontology》 |标签体系&标签扩展&兴趣标签&概念标签 |
| 《Meta-Learning for Qery Conceptualization at Web Scale》 |标签体系&标签扩展&兴趣标签&概念标签 |
| 《AliCoCo: Alibaba E-commerce Cognitive Concept Net》 |标签体系&标签扩展&兴趣标签&概念标签 |
| 《Octet: Online Catalog Taxonomy Enrichment with Self-Supervision》 |标签体系&标签扩展&兴趣标签&概念标签 |
| 《Scaling Up Open Tagging from Tens to Thousands: Comprehension Empowered Attribute Value Extraction from Product Title》 |标签生成 |
| 《Microblog Hashtag Generation via Encoding Conversation Contexts》 |标签生成 |
| 《Cognitive Representation Learning of Self-Media Online Article Quality》 |文本审核&质量 |
| 《Spam Review Detection with Graph Convolutional Networks》 |文本审核&质量 |
| 《Abusive Language Detection with Graph Convolutional Networks》 |文本审核&质量 |
| 《Weak Supervision for Fake News Detection via Reinforcement Learning》 |文本审核&质量 |
| 《Coherent Comment Generation for Chinese Articles with a Graph-to-Sequence Model》 |评论生成&改写 |
| 《Deep Active Learning for Short-Text Classification》 |主动学习 |
| 《EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks》 |数据增强 |
| 《UNSUPERVISED DATA AUGMENTATION FOR CONSISTENCY TRAINING》 |半监督学习 |
| 《Data Programming:Creating Large Training Sets, Quickly》 |半监督学习 |
| 《Rethinking the Value of Labels for Improving Class-Imbalanced Learning》 |半监督学习 |
| 《Extreme Multi-label Loss Functions for Recommendation,Tagging, Ranking & Other Missing Label Applications》 |多标签残缺 |
| 《基于不完整标签信息的多标签分类问题研究》 |多标签残缺 |
| 《Dice loss for data-imbalance NLP tasks》 |样本不均衡 |
| 《Meta-Weight-Net: Learning an Explicit Mapping For Sample Weighting》 |样本不均衡 |
| 《ehensive Introduction to Label Noise》 |噪声标签 |
| 《Classification in the Presence of Label Noise: a Survey》 |噪声标签 |
| 《Image Classification with Deep Learning in the Presence of Noisy Labels: A Survey》 |噪声标签 |
| 《Confident Learning: Estimating Uncertainty in Dataset Labels》 |噪声标签 |
| 《Co-teaching: Robust Training of Deep Neural Networks with Extremely Noisy Labels》 |噪声标签 |
| 《Learning with Noisy Label-深度学习廉价落地》 |噪声标签 |
| 《TextBrewer: An Open-Source Knowledge Distillation Toolkit for Natural Language Processing》 |知识蒸馏 |
| 《Mixed Precision Training》 |量化加速 |
| 《Why Should I Trust You? : Explaning the Predictions of Any Classifier》 |模型可解释性 |
| 《Analyzing and Interpreting Neural Networks for NLP: A Report on the First BlackboxNLP Workshop》 |模型可解释性 |
| 《NeuralClassifier: An Open-source Neural Hierarchical Multi-label Text Classification Toolkit》 |算法框架&工具 |
| 《Familia: A Configurable Topic Modeling Framework for Industrial Text Engineering》 |算法框架&工具 |
| 《LightLDA: Big Topic Models on Modest Computer Clusters》 |算法框架&工具 |
| 《DeepPavlov: Open-Source Library for Dialogue Systems》 |算法框架&工具 |
| 《AllenNLP Interpret: A Framework for Explaining Predictions of NLP Models》 |算法框架&工具 |
| 《Neural Network Models for Paraphrase Identification, Semantic Textual Similarity, Natural Language Inference, and Question Answering》 |其他 |
| 《Analysis Methods in Neural Language Processing: A Survey》 |其他 |
| 《Deep Double Descent: Where Bigger Models and More Data Hurt》 |其他 |
| 《中文信息处理发展报告》 |其他 |
| 《Modern Deep Learning Techniques Applied to Natural Language Processing》 |其他 |








