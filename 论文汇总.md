|编号  |  名称   | 目录  |
|  ----  | ----  |----  | 
| 1  | 《A State-of-the-Art Survey on Deep Learning Theory and Architectures》 |机器学习&深度学习综述 |
| 2  | 《Deep Learning》 |机器学习&深度学习综述 |
| 3  | 《learning internal representation by error propagation》 |DNN |
| 4  | 《LONG SHORT-TERM MEMORY》 |RNN |
| 5  | 《Gradient-Based Learning Applied to Document Recognition》 |CNN |
| 6  | 《Attention Is All You Need》 |Transformer |
| 7  | 《Star-Transformer》 |Transformer |
| 8  | 《Transformer-XL: Language Modeling with Longer-Term Dependency》 |Transformer |
| 9  | 《An Introductory Survey on Attention Mechanisms in NLP Problems》 |Attention机制&指针网络&记忆网络&深度图灵机 |
| 10  | 《Pointer Networks》 |Attention机制&指针网络&记忆网络&深度图灵机 |
| 11  | 《Attention-Based LSTM for Psychological Stress Detection from Spoken Language Using Distant Supervision》 |Attention机制&指针网络&记忆网络&深度图灵机 |
| 12  | 《End-To-End Memory Networks》 |Attention机制&指针网络&记忆网络&深度图灵机 |
| 13  | 《Neural Turing Machines》 |Attention机制&指针网络&记忆网络&深度图灵机 |
| 14  | 《Adversarial Attacks on Deep Learning Models in Natural Language Processing: A Survey》 |对抗攻击 |
| 15  | 《TextAttack: A Framework for Adversarial Attacks, Data Augmentation, and Adversarial Training in NLP》 |对抗攻击 |
| 16  | 《Tackling Graphical NLP problems with Graph Recurrent Networks》 |图网络 |
| 17  | 《阿尔伯塔大学博士毕业论文：基于图结构的自然语言处理》 |图网络 |
| 18  | 《Convolutional Networks on Graphs for Learning Molecular Fingerprints》 |图网络 |
| 19  | 《SEMI-SUPERVISED CLASSIFICATION WITH GRAPH CONVOLUTIONAL NETWORKS》 |图网络 |
| 20  | 《The graph neural network model》 |图网络 |
| 21  | 《Deepwalk: Online learning of social representations》 |图网络 |
| 22  | 《SkipGram model on the generated random walks》 |图网络 |
| 23  | 《HOW POWERFUL ARE GRAPH NEURAL NETWORKS?》 |图网络 |
| 24  | 《Learning Convolutional Neural Networks for Graphs》 |图网络 |
| 25  | 《Graph Neural Networks:A Review of Methods and Applications》 |图网络 |
| 26  | 《A Comprehensive Survey on Graph Neural Networks》 |图网络 |
| 27  | 《Deep Learning on Graphs: A Survey》 |图网络 |
| 28  | 《LINE: Large-scale Information Network Embedding》 |图网络 |
| 29  | 《Graph Attention Networks》 |图网络 |
| 30  | 《struc2vec: Learning Node Representations from Structural Identity》 |图网络 |
| 31  | 《GraphSAINT: Graph Sampling Based Inductive Learning Method》 |图网络 |
| 32  | 《GraphSage: Graph Sampling Based Inductive Learning Method》 |图网络 |
| 33  | 《DROPEDGE: TOWARDS DEEP GRAPH CONVOLUTIONAL NETWORKS ON NODE CLASSIFICATION》 |图网络 |
| 34  | 《Evolution of Transfer Learning in Natural Language Processing》 |迁移学习 |
| 35  | 《Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer》 |迁移学习 |
| 36  | 《Domain-Adversarial Training of Neural Networks》 |领域适应 |
| 37  | 《Auto-WEKA: Combined Selection and Hyperparameter Optimization of Classification Algorithms》 |AutoML |
| 38  | 《AutoGluon-Tabular: Robust and Accurate AutoML for Structured Data》 |AutoML |
| 39  | 《A Survey on Causal Inference》 |因果推断 |
| 40  | 《迈向第三代人工智能》 |常识AI |
| 41  | 《DEEP LEARNING FOR SYSTEM 2 PROCESSING，YOSHUA BENGIO》 |常识AI |
| 42  | 《FROM SYSTEM 1 DEEP LEARNING TO SYSTEM 2 DEEP LEARNING,YOSHUA BENGIO》 |常识AI |
| 43  | 《Cognitive Graph for Multi-Hop Reading Comprehension at Scale》 |常识AI |
| 44  | 《Auto-Encoding Variational Bayes》 |贝叶斯神经网络 |
| 45  | 《Cold-Start and Interpretability: Turning Regular Expressions into Trainable Recurrent Neural Networks》 |神经逻辑推理 |
| 46  | 《Neural Logic Reasoning》 |神经逻辑推理 |
| 47  | 《Recent Trends in Deep Learning Based Natural Language Processing》 |自然语言处理综述 |
| 48  | 《Pre-trained Models for Natural Language Processing: A Survey》 |文本预训练模型 |
| 49  | 《Semi-supervised Sequence Learning》 |文本预训练模型 |
| 50  | 《Learned in Translation: Contextualized Word Vectors》 |文本预训练模型 |
| 51  | 《Semi-supervised sequence tagging with bidirectional language models》 |文本预训练模型 |
| 52  | 《Universal Language Model Fine-tuning for Text Classification》 |文本预训练模型 |
| 53  | 《Deep contextualized word representation》 |文本预训练模型 |
| 54  | 《Improving Language Understanding by Generative Pre-Training》 |文本预训练模型 |
| 55  | 《Language Models are Unsupervised Multitask Learners》 |文本预训练模型 |
| 56  | 《Language Models are Few-Shot Learners》 |文本预训练模型 |
| 57  | 《BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding》 |文本预训练模型 |
| 58  | 《Cross-lingual Language Model Pretraining》 |文本预训练模型 |
| 59  | 《MASS: Masked Sequence to Sequence Pre-training for Language Generation》 |文本预训练模型 |
| 60  | 《Unified Language Model Pre-training for Natural Language Understanding and Generation》 |文本预训练模型 |
| 61  | 《UniLMv2: Pseudo-Masked Language Models for Unified Language Model Pre-Training》 |文本预训练模型 |
| 62  | 《MPNet: Masked and Permuted Pre-training for Language Understanding》 |文本预训练模型 |
| 63  | 《RoBERTa: A Robustly Optimized BERT Pretraining Approach》 |文本预训练模型 |
| 64  | 《ALBERT: A Lite BERT for Self-supervised Learning of Language Representations》 |文本预训练模型 |
| 65  | 《Pre-Training with Whole Word Masking for Chinese BERT》 |文本预训练模型 |
| 66  | 《ERNIE: Enhanced Language Representation with Informative Entities》 |文本预训练模型 |
| 67  | 《ERNIE: Enhanced Representation through Knowledge Integration》 |文本预训练模型 |
| 68  | 《ERNIE 2.0: A CONTINUAL PRE-TRAINING FRAMEWORK FORLANGUAGE》 |文本预训练模型 |
| 69  | 《ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators》 |文本预训练模型 |
| 70  | 《K-BERT: Enabling Language Representation with Knowledge Graph》 |文本预训练模型 |
| 71  | 《StructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding》 |文本预训练模型 |
| 72  | 《Semantics-aware BERT for Language Understanding》 |文本预训练模型 |
| 73  | 《XLNet: Generalized Autoregressive Pretraining for Language Understanding》 |文本预训练模型 |
| 74  | 《Longformer: The Long-Document Transformer》 |文本预训练模型 |
| 75  | 《Big Bird: Transformers for Longer Sequences》 |文本预训练模型 |
| 76  | 《Well-Read Students Learn Better: On the Importance of Pre-training Compact Models》 |文本预训练模型 |
| 77  | 《ALBERT: A Lite BERT for Self-supervised Learning of Language Representations》 |文本预训练模型 |
| 78  | 《DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter》 |文本预训练模型 |
| 79  | 《TinyBERT: Distilling BERT for Natural Language Understanding》 |文本预训练模型 |
| 80  | 《FastBERT: a Self-distilling BERT with Adaptive Inference Time》 |文本预训练模型 |
| 81  | 《Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer》 |文本预训练模型 |
| 82  | 《Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism》 |文本预训练模型 |
| 83  | 《THE COST OF TRAINING NLP MODELS A CONCISE OVERVIEW》 |文本预训练模型 |
| 84  | 《SpanBERT: Improving Pre-training by Representing and Predicting Spans》 |文本预训练模型 |
| 85  | 《Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks》 |文本预训练模型 |
| 86  | 《Pre-Training with Whole Word Masking for Chinese BERT》 |文本预训练模型 |
| 87  | 《NEZHA: Neural Contextualized Representation for Chinese Language Understanding》 |文本预训练模型 |
| 88  | 《ZEN: Pre-training Chinese (Z) Text Encoder Enhanced by N-gram Representations 》 |文本预训练模型 |
| 89  | 《Revisiting Pre-Trained Models for Chinese Natural Language Processing》 |文本预训练模型 |
| 90  | 《Efficient Estimation of Word Representations in Vector Space》 |文本向量化 |
| 91  | 《Distributed Representations of Words and Phrases and their Compositionality》 |文本向量化 |
| 92  | 《word2vec Parameter Learning Explained》 |文本向量化 |
| 93  | 《word2vec Explained: Deriving Mikolov et al.’s Negative-Sampling Word-Embedding Method》 |文本向量化 |
| 94  | 《Enriching Word Vectors with Subword Information》 |文本向量化 |
| 95  | 《Bag of Tricks for Efficient Text Classification》 |文本向量化 |
| 96  | 《A Neural Probabilistic Language Model》 |文本向量化 |
| 97  | 《Universal Sentence Encoder for English》 |文本向量化 |
| 98  | 《Distributed Representations of Sentences and Documents》 |文本向量化 |
| 99  | 《A Convolutional Neural Network for Modelling Sentences》 |文本向量化 |
| 100  | 《Multi-Criteria Chinese Word Segmentation with Transformer》 |中文分词 |
| 101  | 《Multi-Grained Chinese Word Segmentation》 |中文分词 |
| 102  | 《基于文档主题结构的关键词抽取方法研究》 |关键词提取 |
| 103  | 《Topic-Aware Neural Keyphrase Generation for Social Media Language》 |关键词提取 |
| 104  | 《Context-Aware Document Term Weighting for Ad-Hoc Search》 |关键词提取 |
| 105  | 《Title-Guided Encoding for Keyphrase Generation》 |关键词提取 |
| 106  | 《深度文本匹配综述》 |文本相似度计算 |
| 107  | 《A Deep Look into Neural Ranking Models for Information Retrieval》 |文本相似度计算 |
| 108  | 《Deep Learning Based Text Classification: A Comprehensive Review》 |文本分类 |
| 109  | 《Hierarchical Multi-Label Classification Networks》 |文本分类 |
| 110  | 《Large-Scale Hierarchical Text Classification with Recursively Regularized Deep Graph-CNN》 |文本分类 |
| 111  | 《Hierarchical Taxonomy-Aware and Attentional Graph Capsule RCNNs for Large-Scale Multi-Label Text Classification》 |文本分类 |
| 112  | 《Learning Deep Latent Spaces for Multi-Label Classification》 |文本分类 |
| 113  | 《Joint Embedding of Words and Labels for Text Classification》 |文本分类 |
| 114  | 《Enhancing Local Feature Extraction with Global Representation for Neural Text Classification》 |文本分类 |
| 115  | 《Description Based Text Classification with Reinforcement Learning》 |文本分类 |
| 116  | 《Document Modeling with Gated Recurrent Neural Network for Sentiment Classification》 |文本分类 |
| 117  | 《Neural Attentive Bag-of-Entities Model for Text Classification》 |文本分类 |
| 118  | 《An Interactive Multi-Task Learning Network for End-to-End Aspect-Based Sentiment Analysis》 |情感分析 |
| 119  | 《Deep Learning for Aspect-Level Sentiment Classification: Survey, Vision, and Challenges》 |情感分析 |
| 120  | 《Deep learning for sentiment analysis: A survey》 |情感分析 |
| 121  | 《Hierarchical Topic Models and the Nested Chinese Restaurant Process》 |主题模型 |
| 122  | 《Topic Modeling for Personalized Recommendation of Volatile Items》 |主题模型 |
| 123  | 《Topic Memory Networks for Short Text Classification》 |主题模型 |
| 124  | 《Mixing Dirichlet Topic Models and Word Embeddings to Make lda2vec》 |主题模型 |
| 125  | 《Discovering Discrete Latent Topics with Neural Variational Inference》 |主题模型 |
| 126  | 《Federated Topic Modeling》 |主题模型 |
| 127  | 《ATM:Adversarial-neural Topic Model》 |主题模型 |
| 128  | 《Neural Machine Reading Comprehension: Methods and Trends》 |阅读理解 |
| 129  | 《Neural Reading Comprehension And Beyond》 |阅读理解 |
| 130  | 《Get To The Point: Summarization with Pointer-Generator Networks》 |文本改写&生成 |
| 131  | 《Rigid Formats Controlled Text Generation》 |文本改写&生成 |
| 132  | 《CGMH: Constrained Sentence Generation by Metropolis-Hastings Sampling》 |文本改写&生成 |
| 133  | 《UNSUPERVISED PARAPHRASE GENERATION USING PRE-TRAINED LANGUAGE MODELS》 |文本改写&生成 |
| 134  | 《FASPell: A Fast, Adaptable, Simple, Powerful Chinese Spell Checker Based On DAE-Decoder Paradigm》 |文本检错&纠错 |
| 135  | 《文本纠错的探索与实践》平安人寿：陈乐清 |文本检错&纠错  |
| 136  | 《Get To The Point: Summarization with Pointer-Generator Network》 |摘要生成 |
| 137  | 《Encode, Tag, Realize: High-Precision Text Editing》 |摘要生成 |
| 138  | 《Multi-Source Pointer Network for Product Title Summarization》 |摘要生成 |
| 139  | 《Abstractive Summarization: A Survey of the State of the Art》 |摘要生成 |
| 140  | 《Aspect-Aware Multimodal Summarization for Chinese E-Commerce Products》 |摘要生成 |
| 141  | NULL |NULL |
| 142  | NULL |NULL |
| 143  | NULL |NULL |
| 144  | NULL |NULL |
| 145  | NULL |NULL |
| 146  | NULL |NULL |
| 147  | NULL |NULL |
| 148  | NULL |NULL |
| 149  | NULL |NULL |
| 150  | NULL |NULL |
| 151  | NULL |NULL |
| 152  | NULL |NULL |
| 153  | NULL |NULL |
| 154  | NULL |NULL |
| 155  | NULL |NULL |
| 156  | NULL |NULL |
| 157  | NULL |NULL |
| 158  | NULL |NULL |
| 159  | NULL |NULL |
| 160  | NULL |NULL |
| 161  | NULL |NULL |
| 162  | NULL |NULL |
| 163  | NULL |NULL |
| 164  | NULL |NULL |
| 165  | NULL |NULL |
| 166  | NULL |NULL |
| 167  | NULL |NULL |
| 168  | NULL |NULL |
| 169  | NULL |NULL |
| 170  | NULL |NULL |
| 171  | NULL |NULL |
| 172  | NULL |NULL |
| 173  | NULL |NULL |
| 174  | NULL |NULL |
| 175  | NULL |NULL |
| 176  | NULL |NULL |
| 177  | NULL |NULL |
| 178  | NULL |NULL |
| 179  | NULL |NULL |
| 180  | NULL |NULL |
| 181  | NULL |NULL |
| 182  | NULL |NULL |
| 183  | NULL |NULL |
| 184  | NULL |NULL |
| 185  | NULL |NULL |
| 186  | NULL |NULL |
| 187  | NULL |NULL |
| 188  | NULL |NULL |
| 189  | NULL |NULL |
| 190  | NULL |NULL |
| 191  | NULL |NULL |
| 192  | NULL |NULL |
| 193  | NULL |NULL |
| 194  | NULL |NULL |
| 195  | NULL |NULL |
| 196  | NULL |NULL |
| 197  | NULL |NULL |
| 198  | NULL |NULL |
| 199  | NULL |NULL |
| 200  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
| NULL  | NULL |NULL |
