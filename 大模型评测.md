|名称  |  来源   | 说明  |状态   | 备注  |
|  ----  | ----  |----  | ----  |----  |
| NULL  | NULL |NULL |NULL |NULL |
| NULL  | NULL |NULL |NULL |NULL |
| 《ModelScope-Agent: Building Your Customizable Agent System with Open-source Large Language Models》| arxiv 2023| 阿里的智能体框架ModelScope-Agent：<br/>1 核心组件：<br/>-Tool Retrieval<br/>-Memory Control<br/>-Task Planning<br/>-Tool Use<br/>-API Execution<br/>-Response Generation<br/>2 评测指标<br/>-ROUGE-L：最终回复结果是否满足预期<br/>-Action EM：API选择是否满足预期<br/>-Argument F1：参数选择是否满足预期<br/>3 参考点：<br/>-大模型处理前，统一进行了API和知识的检索<br/>-没有做专门的任务规划，直接融合在工具使用的过程中了<br/>-训练策略Weighted LM：更专注在API选择和参数填充上| NULL | NULL |
| 《TASKBENCH: BENCHMARKING LARGE LANGUAGE MODELS FOR TASK AUTOMATION》| arxiv2023| 任务拆解数据构建和评测：<br/>1 数据构建（DATASET CONSTRUCTION）：<br/>-基于resource and temporal dependencies手工来构建图：工具来源Hugging Face，Multimedia，Daily Life APIs<br/>-基于Node、Chain、DAG维度进行采样，然后生成Instruct（BACK-INSTRUCT）；<br/>-评估质量；<br/>2 能力评估（TASKEVAL）：<br/>-进行TASK DECOMPOSITION、TOOL INVOCATION、PARAMETER PREDICTION三个维度的评估（一个Prompt，一次推理完成）；<br/>-对比人类评估和数据集评估的一致性；<br/>-分析和模型任务拆解能力相关的因素；<br/>3 启示<br/>-基于候选工具确认任务拆解的粒度| NULL | NULL |
| 《T-Eval: Evaluating the Tool Utilization Capability of Large Language Models Step by Step》| arxiv2024| 智能体评测榜单：https://open-compass.github.io/T-Eval/leaderboard_zh.html<br/>1 核心维度：<br/>-PLAN：规划（拆解多个步骤）<br/>-REASON：当前步骤<br/>-RETRIEVE：API选择<br/>-UNDERSTAND：参数填充<br/>-INSTRUCT:最需要执行的动作做总结<br/>-REVIEW：判断是否可以工具使用能够完成用户的需求<br/>2 工具来源和数量<br/>-来自ToolBench（论文 TooLLLM）<br/>-23,305 testcases in total<br/>3 商用大模型和开源大模型对比评测和分析<br/>-首先要follow格式（很多模型做不到）<br/>-follow格式和能够执行任务没有特别的相关性 | NULL | NULL |
| 《GPT-FATHOM: BENCHMARKING LARGE LANGUAGE MODELS TO DECIPHER THE EVOLUTIONARY PATH TOWARDS GPT-4 AND BEYOND》| arxiv2023| 1 针对开源和闭源模型的全面统一评估：<br/>-Knowledge<br/>-Reasoning<br/>-Comprehension<br/>-Math<br/>-Coding<br/>-Multilingual<br/>-Safety<br/>2 对模型特性的讨论：<br/>-OpenAI vs. non-OpenAI LLMs<br/>-Closed-source vs. open-source LLMs<br/>-OpenAI API-based vs. Web-version LLMs<br/>-Seesaw phenomenon of LLM capabilities<br/>-Impacts of pretraining with code data<br/>-Impacts of SFT and RLHF<br/>-Impacts of the number of “shots”<br/>-Impacts of CoT prompting<br/>-Prompt sensitivity<br/>-Sampling variance<br/>3 其中，提到的FeedME（(as explained by OpenAI3, FeedME means SFTon human-written demonstrations and on model samples rated 7/7 by human labelers on an overall quality score）没能理解；| NULL | https://mp.weixin.qq.com/s/-AWkDzAzoyQNmgYXuC6B4w |
