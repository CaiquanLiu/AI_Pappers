|名称  |  来源   | 说明  |状态   | 备注  |
|  ----  | ----  |----  | ----  |----  |
| 《Attention Is All You Need》  | NIPS2017 |Transformer原始论文：<br/>Encoder；<br/>Decoder；<br/>位置编码；<br/>Mask（padding/decoder）；|done |NULL |
| 《Star-Transformer》  | NAACL2019	 |NULL |NULL |NULL |
| 《Transformer-XL: Language Modeling with Longer-Term Dependency》  | ICLR2019 |单元格 |单元格 |单元格 |
| NULL  | NULL |NULL |NULL |NULL |
| NULL  | NULL |NULL |NULL |NULL |
| NULL  | NULL |NULL |NULL |NULL |
| NULL  | NULL |NULL |NULL |NULL |
| NULL  | NULL |NULL |NULL |NULL |
| NULL  | NULL |NULL |NULL |NULL |
| NULL  | NULL |NULL |NULL |NULL |
